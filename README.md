# Google Ads Data Cleaning & Visualization  

ğŸ“Š **Proyecto acadÃ©mico â€“ CoderHouse Data Science I**  
Este proyecto consiste en la **limpieza, exploraciÃ³n y visualizaciÃ³n** de un dataset de **Google Ads**, aplicando tÃ©cnicas de **data cleaning y anÃ¡lisis exploratorio (EDA)** con Python.  

---

# Google Ads Data Cleaning & Visualization  

ğŸ“Œ Este repositorio contiene un proyecto de **Data Cleaning y ExploraciÃ³n de Datos (EDA)** aplicado a un dataset de **Google Ads**, realizado como parte de la carrera de Data Science en CoderHouse.  

---

## â–¶ï¸ CÃ³mo abrir el notebook  

Puedes revisar el proyecto de dos maneras:  

1. **Ver en GitHub**:  
   ğŸ”— [Notebook en GitHub](https://github.com/meliluc/google-ads-data-cleaning-visualization/blob/main/ProyectoDSParteI_Lucero_Antonietti.ipynb)  

2. **Abrir y ejecutar en Google Colab** (recomendado):    
   [![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/meliluc/google-ads-data-cleaning-visualization/blob/main/ProyectoDSParteI_Lucero_Antonietti.ipynb)  

---

## ğŸ› ï¸ Herramientas Utilizadas
- Python  
- Pandas  
- NumPy  
- Seaborn  
- Matplotlib  
- Jupyter / Google Colab

---

## ğŸ¯ Objetivos
- Realizar **data cleaning** y detecciÃ³n de valores perdidos.  
- Definir **preguntas de investigaciÃ³n** e hipÃ³tesis iniciales.  
- Generar **visualizaciones univariadas, bivariadas y multivariadas**.  
- Interpretar los resultados vinculÃ¡ndolos con el negocio.  

---

## ğŸ” 1. ExploraciÃ³n inicial
- Cargamos el dataset en un **DataFrame de Pandas**.  
- Revisamos dimensiones, tipos de datos y valores nulos (`.info()`, `.isnull().sum()`).  
- Identificamos problemas tÃ­picos de datos crudos:  
  - Fechas con formatos mezclados.  
  - Variables monetarias con sÃ­mbolos (`$`, `,`).  
  - Valores faltantes (`NaN`).  
  - CategorÃ­as duplicadas por mayÃºsculas/minÃºsculas (ej: *Mobile, mobile, MOBILE*).  

---

## ğŸ§¹ 2. Limpieza de datos

**a) Fechas**  
- Creamos una funciÃ³n para parsear mÃºltiples formatos (`2024/11/16`, `16-11-2024`, `2024-11-04`).  
- Convertimos `Ad_Date` a tipo `datetime64[ns]`.  

**b) Variables monetarias**  
- Quitamos sÃ­mbolos y separadores en `Cost` y `Sale_Amount`.  
- Convertimos esas columnas a `float`.  

**c) Tipos de datos**  
- Columnas categÃ³ricas (`Campaign_Name`, `Location`, `Device`, `Keyword`) â†’ `string`.  
- Variables numÃ©ricas (`Clicks`, `Impressions`, `Conversions`, `Leads`) â†’ `float`.  

**d) Valores faltantes**  
- Detectamos nulos en columnas clave.  
- Los rellenamos con la **mediana** de cada columna numÃ©rica (mÃ¡s robusta que la media).  

**e) NormalizaciÃ³n de categorÃ­as**  
- Unificamos categorÃ­as de `Device` en minÃºsculas (`desktop`, `mobile`, `tablet`).  

---

## ğŸ“Š 3. Control de calidad
- Verificamos nulos tras la limpieza (`.isnull().sum()`).  
- Revisamos valores atÃ­picos (ej: ceros en columnas monetarias).  
- Confirmamos consistencia de tipos de datos finales.  

---

## ğŸ“ˆ 4. AnÃ¡lisis y visualizaciones
- Creamos grÃ¡ficos multivariados para explorar relaciones:  
  - **Ejemplo 1**: `Cost vs Sale_Amount`, tamaÃ±o proporcional a `Clicks`, color por `Device`.  
  - **Ejemplo 2**: Figura **FacetGrid** separando mÃ©tricas por dispositivo.  
- AcompaÃ±amos cada visualizaciÃ³n con anÃ¡lisis descriptivo de patrones.  

---

## ğŸ“Š 5. EstadÃ­sticos descriptivos
- Calculamos resÃºmenes numÃ©ricos (`mean`, `median`, `std`) para variables clave (`Cost`, `Clicks`, `Sale_Amount`).  
- Estos respaldaron lo observado en los grÃ¡ficos.  

---

## ğŸ“ 6. Conclusiones preliminares
- Los datos sin limpiar generaban **patrones artificiales** (ej: forma de cruz en scatterplots).  
- Tras la limpieza, las relaciones **Cost â†’ Sale_Amount** fueron mÃ¡s consistentes.  
- El dataset quedÃ³ preparado para futuros **modelos predictivos** (ej: predecir ventas a partir de inversiÃ³n, clics, dispositivo, etc.).  

---

## ğŸ“‚ Estructura del Repositorio

â”œâ”€â”€ ProyectoDS_ParteI_LuceroAntonietti.ipynb   # Notebook principal â”œâ”€â”€ dataset_google_ads.csv                     # Dataset utilizado â””â”€â”€ README.md                                  # DescripciÃ³n del proyecto


---

## ğŸš€ PrÃ³ximos pasos: PredicciÃ³n en el Proyecto  

Tras la limpieza y el anÃ¡lisis exploratorio, el siguiente objetivo es avanzar hacia la **modelizaciÃ³n predictiva** para estimar el monto de ventas (`Sale_Amount`) en funciÃ³n de otras variables.  

### ğŸ¯ 1. Definir el objetivo de predicciÃ³n  
ğŸ‘‰ **Predecir `Sale_Amount` (variable continua)** a partir de variables como `Cost`, `Clicks`, `Impressions`, `Device`, `Location`, etc.  
â¡ï¸ Se trata de un **problema de regresiÃ³n**.  

---

### ğŸ› ï¸ 2. PreparaciÃ³n de los datos para Machine Learning  
- **Features (X)**: `Cost`, `Clicks`, `Impressions`, `Leads`, `Device`, `Location`.  
- **Target (y)**: `Sale_Amount`.  
- **CodificaciÃ³n de variables categÃ³ricas** (`Device`, `Location`, etc.) con *OneHotEncoding*.  
- **Escalado de datos** para algoritmos sensibles a la escala (ej. RegresiÃ³n lineal, SVM).  
- **DivisiÃ³n Train/Test** con `train_test_split` (ej: 80/20).  

---

### ğŸ¤– 3. Entrenamiento de modelos de regresiÃ³n  
Se evaluarÃ¡n diferentes algoritmos:  
- **RegresiÃ³n Lineal** (baseline, interpretable).  
- **Ãrboles de DecisiÃ³n / Random Forest** (captura de relaciones no lineales).  
- **Gradient Boosting / XGBoost** (modelos mÃ¡s potentes y precisos).  

---

### ğŸ“Š 4. EvaluaciÃ³n de modelos  
Se utilizarÃ¡n mÃ©tricas clave:  

- **RÂ² (Coeficiente de determinaciÃ³n)** â†’ mide quÃ© tan bien el modelo explica la variabilidad de las ventas (`Sale_Amount`).  
- **RMSE (Error cuadrÃ¡tico medio)** â†’ indica cuÃ¡nto se equivoca en promedio el modelo en sus predicciones.  

Estas mÃ©tricas permitirÃ¡n comparar la performance de los distintos algoritmos (RegresiÃ³n Lineal, Random Forest, Gradient Boosting).  

---

### ğŸ”® 5. InterpretaciÃ³n y conclusiones  
- Identificar las **variables con mayor influencia** en las ventas (`feature importance`).  
- Responder preguntas de negocio:  
  - Â¿El **costo** es el factor mÃ¡s determinante?  
  - Â¿El nÃºmero de **clicks** predice mejor las ventas que las impresiones?  
  - Â¿El **dispositivo o la ubicaciÃ³n** generan diferencias significativas?  
- Determinar si el modelo tiene **precisiÃ³n suficiente** para ser utilizado en un entorno real de toma de decisiones.  

---

## ğŸ‘©â€ğŸ’» Autora  

**Melina Lucero Antonietti**  

ğŸ”— [LinkedIn](https://www.linkedin.com/in/melina-lucero/) 
ğŸ’» [GitHub](https://github.com/meliluc)  

---
